{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859d207e",
   "metadata": {},
   "source": [
    "# Instalaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c19d0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from opacus import PrivacyEngine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77eac3",
   "metadata": {},
   "source": [
    "# Paso 1: Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74441b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y dividir el conjunto de datos\n",
    "breast_dataset = load_breast_cancer()\n",
    "X = breast_dataset.data\n",
    "y = breast_dataset.target\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5cb51",
   "metadata": {},
   "source": [
    "# Paso 2: Definir el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1146898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 50)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        # No necesitas una capa Sigmoid si usas BCEWithLogitsLoss\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca53c54",
   "metadata": {},
   "source": [
    "# Paso 3: Clase Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cefbafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, data, target, client_number):\n",
    "        self.client_number = client_number\n",
    "        self.model = Net()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        dataset = TensorDataset(data, target.view(-1, 1))\n",
    "        self.data_loader = DataLoader(dataset, batch_size=15, shuffle=True)\n",
    "        self.privacy_engine = PrivacyEngine()  \n",
    "        self.model, self.optimizer, self.data_loader = self.privacy_engine.make_private_with_epsilon(\n",
    "            module=self.model,\n",
    "            optimizer=self.optimizer,\n",
    "            data_loader=self.data_loader,\n",
    "            epochs=100,\n",
    "            target_epsilon=100,\n",
    "            target_delta=0.001,\n",
    "            max_grad_norm=1,\n",
    "        )\n",
    "        \n",
    "    def train(self, epochs=5):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            for data, target in self.data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Calcular el accuracy en los datos de entrenamiento\n",
    "                pred = torch.sigmoid(output).round()\n",
    "                correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "                total_correct += correct\n",
    "                total_samples += target.size(0)\n",
    "            \n",
    "            train_accuracy = total_correct / total_samples  \n",
    "            epsilon = self.privacy_engine.get_epsilon(delta=0.001)  \n",
    "            \n",
    "            # Imprimir la información, incluyendo el número del cliente\n",
    "            print(f\"Client: {self.client_number}, Epoch: {epoch+1}, Loss: {loss.item()}, Epsilon: {epsilon}, Train ACC: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    # Método de evaluación  con la data de test para cada cliente\n",
    "    def evaluate(self, test_data, test_target):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.model(test_data)\n",
    "            pred = torch.sigmoid(output).round()\n",
    "            correct = pred.eq(test_target.view_as(pred)).sum().item()\n",
    "            accuracy = correct / len(test_target)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ba731",
   "metadata": {},
   "source": [
    "# Paso 4: Clase Servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8f32871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.global_model = Net()\n",
    "\n",
    "    def aggregate(self, client_models):\n",
    "        global_dict = {}\n",
    "        for k in client_models[0].keys():\n",
    "            adjusted_key = k.replace(\"_module.\", \"\")  \n",
    "            global_dict[adjusted_key] = torch.stack([client_models[i][k] for i in range(len(client_models))], 0).mean(0)\n",
    "        self.global_model.load_state_dict(global_dict)\n",
    "\n",
    "    def evaluate(self, test_data, test_target):\n",
    "        self.global_model.eval()  \n",
    "        with torch.no_grad():\n",
    "            output_global = self.global_model(test_data)  # y aquí también\n",
    "            pred_global = torch.sigmoid(output_global).round()\n",
    "            correct_global = pred_global.eq(test_target.view_as(pred_global)).sum().item()\n",
    "            accuracy_global = correct_global / len(test_target)\n",
    "        return accuracy_global\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c9920",
   "metadata": {},
   "source": [
    "# Paso 5: Entrenamiento y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8c2c8b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 1, Epoch: 1, Loss: 0.618086040019989, Epsilon: 7.229711840478823, Train ACC: 93.14%\n",
      "Client: 1, Epoch: 2, Loss: 0.5472254157066345, Epsilon: 9.618787125042179, Train ACC: 89.68%\n",
      "Client: 1, Epoch: 3, Loss: 0.5537917613983154, Epsilon: 11.56035669629223, Train ACC: 94.51%\n",
      "Client: 1, Epoch: 4, Loss: 0.4533534049987793, Epsilon: 13.27581426442283, Train ACC: 94.94%\n",
      "Client: 1, Epoch: 5, Loss: 0.4833025634288788, Epsilon: 14.848469660834416, Train ACC: 94.32%\n",
      "Client: 2, Epoch: 1, Loss: 0.6451927423477173, Epsilon: 7.229711840478823, Train ACC: 62.50%\n",
      "Client: 2, Epoch: 2, Loss: 0.6024797558784485, Epsilon: 9.618787125042179, Train ACC: 74.36%\n",
      "Client: 2, Epoch: 3, Loss: 0.5956522822380066, Epsilon: 11.56035669629223, Train ACC: 80.92%\n",
      "Client: 2, Epoch: 4, Loss: 0.5821568369865417, Epsilon: 13.27581426442283, Train ACC: 83.14%\n",
      "Client: 2, Epoch: 5, Loss: 0.4995638132095337, Epsilon: 14.848469660834416, Train ACC: 83.94%\n",
      "Client: 3, Epoch: 1, Loss: 0.6860606670379639, Epsilon: 7.229711840478823, Train ACC: 30.06%\n",
      "Client: 3, Epoch: 2, Loss: 0.6961191892623901, Epsilon: 9.618787125042179, Train ACC: 56.95%\n",
      "Client: 3, Epoch: 3, Loss: 0.653972864151001, Epsilon: 11.56035669629223, Train ACC: 77.85%\n",
      "Client: 3, Epoch: 4, Loss: 0.6066589951515198, Epsilon: 13.27581426442283, Train ACC: 85.71%\n",
      "Client: 3, Epoch: 5, Loss: 0.5980014801025391, Epsilon: 14.848469660834416, Train ACC: 86.36%\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento y evaluación con la división de prueba para cada cliente:\n",
    "\n",
    "client_data = torch.chunk(X_train_tensor, 3)\n",
    "client_target = torch.chunk(y_train_tensor, 3)\n",
    "\n",
    "\n",
    "clients = [Client(client_data[i], client_target[i], i+1) for i in range(3)]\n",
    "client_models = [client.train() for client in clients]\n",
    "server = Server()\n",
    "server.aggregate(client_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1f05057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy cliente 1: 94.74%\n",
      "Accuracy cliente 2: 84.21%\n",
      "Accuracy cliente 3: 80.70%\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del ACC para cada cliente con la división de entrenamiento\n",
    "for i in range(3):\n",
    "    accuracy = clients[i].evaluate(X_test_tensor, y_test_tensor)\n",
    "    print(f'Accuracy cliente {i+1}: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca661d",
   "metadata": {},
   "source": [
    "# Paso 6. Validación del Modelo Global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b2fc150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model accuracy: 79.82%\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del ACC del modelo global entrenado con la división de prueba\n",
    "server = Server()\n",
    "server.aggregate(client_models)\n",
    "\n",
    "# Evaluación del modelo global\n",
    "\n",
    "global_accuracy = server.evaluate(X_test_tensor, y_test_tensor)\n",
    "print(f'Global model accuracy: {global_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472a22a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ✨ Inspiración\n",
    "\n",
    "Aunque el código no es exactamente el mismo, este proyecto se inspiró en el innovador trabajo realizado por [Yang, Y., Hui, B., Yuan, H., Gong, N., & Cao, Y. (2023). PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation. In Proceedings of the USENIX Security Symposium (Usenix'23)](https://github.com/BHui97/PrivateFL), el cual ofreció valiosas percepciones sobre el aprendizaje federado y la privacidad diferencial. Queremos expresar nuestro agradecimiento a los autores originales y contribuyentes del proyecto que nos inspiró por compartir su conocimiento y recursos con la comunidad de código abierto.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
